{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datasets are the individual .csv's\n",
    "# function to load CSV files from ./archive and return a dictionary.\n",
    "# The key is the file name, and the value is the DataFrame\n",
    "def load_datasets(folder_path):\n",
    "    folder_path = \"./archive\"  # Hardcoded path to ./archive\n",
    "    data_dict = {}  # Create an empty dictionary to store DataFrames\n",
    "    csv_files = os.listdir(folder_path)  # List all files in the folder\n",
    "    for file in csv_files:\n",
    "        if file.endswith(\".csv\"):  # Select only CSV files\n",
    "            full_path = os.path.join(folder_path, file)  # Full path to file\n",
    "            df = pd.read_csv(full_path)  # Read CSV into DataFrame\n",
    "            data_dict[file] = df  # Add to dictionary\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "\n",
    "# function explores basic info about a selected dataset, such as its first 5 rows, column names, data types, etc.\n",
    "def explore_dataset(df):\n",
    "    print(\"\\n---First 5 rows---\")\n",
    "    print(df.head())  # Display first 5 rows\n",
    "    \n",
    "    print(\"\\n---Column names---\")\n",
    "    print(df.columns)  # List column names\n",
    "    \n",
    "    print(\"\\n---Data types---\")\n",
    "    print(df.dtypes)  # Display column data types\n",
    "    \n",
    "    print(\"\\n---Missing values---\")\n",
    "    print(df.isnull().sum())  # Show missing values per column\n",
    "    \n",
    "    print(\"\\n---Summary stats---\")\n",
    "    print(df.describe())  # Summary statistics for numerical columns\n",
    "    print('\\n')\n",
    "\n",
    "# function lists all available datasets (i.e., print the keys from the `data_dict`).\n",
    "def list_available_datasets(data_dict):\n",
    "    print(\"\\n---Available datasets---\\n\")\n",
    "    for dataset in data_dict.keys():  # Iterate over each file name in the dictionary\n",
    "        print(dataset)  # Print the file name\n",
    "\n",
    "# select a dataset from the available list and explore it\n",
    "def select_and_explore_dataset(data_dict):\n",
    "    list_available_datasets(data_dict) #lists all datasets in data_dict\n",
    "    ds_choice = input(\"\\nSelect a dataset to explore: \")\n",
    "    if ds_choice in data_dict.keys(): #checks if users choice is in data_dict\n",
    "        print(f\"\\n---Exploring {ds_choice}---\")\n",
    "        explore_dataset(data_dict[ds_choice]) #if the users choice exists, pass the dataframe to explore_dataset\n",
    "    else:\n",
    "        print(\"---The dataset you selected does not exist.---\")\n",
    "\n",
    "\n",
    "# Merge two datasets (`results.csv` and `races.csv`) based on common column like `raceId`.\n",
    "def merge_results_races(data_dict):\n",
    "    results_df = data_dict[\"results.csv\"]  # Loads race results data from the dict (results.csv)\n",
    "    races_df = data_dict[\"races.csv\"]  # Load the race details data from the dictionary (races.csv)\n",
    "    merged_race_data = pd.merge(results_df, races_df, on='raceId', how=\"left\")  \n",
    "    return merged_race_data  # Return the merged DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataframe):\n",
    "    dataframe.replace({'\\\\N': pd.NA}, inplace=True)\n",
    "\n",
    "    columns_to_remove = [\n",
    "        'resultId', 'position', 'positionOrder', 'time_x', 'fastestLapTime', \n",
    "        'fastestLapSpeed', 'number', 'rank', 'url', \n",
    "        'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', \n",
    "        'fp3_date', 'fp3_time', 'quali_date', 'quali_time', \n",
    "        'sprint_date', 'sprint_time', 'date', 'time_y'\n",
    "    ]\n",
    "    dataframe.drop(columns=columns_to_remove, errors='ignore', inplace=True)\n",
    "\n",
    "    essential_columns = ['raceId', 'driverId', 'grid', 'laps', 'year']\n",
    "    dataframe.dropna(subset=essential_columns, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After further cleaning (updated for predictive purposes):\n",
      "   raceId  driverId  constructorId  grid  points  laps milliseconds  \\\n",
      "0      18         1              1     1    10.0    58      5690616   \n",
      "1      18         2              2     5     8.0    58      5696094   \n",
      "2      18         3              3     7     6.0    58      5698779   \n",
      "3      18         4              4    11     5.0    58      5707797   \n",
      "4      18         5              1     3     4.0    58      5708630   \n",
      "\n",
      "  fastestLap  statusId  year  round  circuitId                   name  \n",
      "0         39         1  2008      1          1  Australian Grand Prix  \n",
      "1         41         1  2008      1          1  Australian Grand Prix  \n",
      "2         41         1  2008      1          1  Australian Grand Prix  \n",
      "3         58         1  2008      1          1  Australian Grand Prix  \n",
      "4         43         1  2008      1          1  Australian Grand Prix  \n"
     ]
    }
   ],
   "source": [
    "cleaned_data = clean_data(merged_data)\n",
    "\n",
    "print(\"\\nAfter further cleaning (updated for predictive purposes):\")\n",
    "print(cleaned_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
